{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JZhh_1S_FSey"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import pickle\n",
    "\n",
    "# Tesseract command path (change this if needed)\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files (x86)\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# Entity to unit map\n",
    "entity_unit_map = {\n",
    "    'width': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'depth': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'height': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'item_weight': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
    "    'maximum_weight_recommendation': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
    "    'voltage': {'kilovolt', 'millivolt', 'volt'},\n",
    "    'wattage': {'kilowatt', 'watt'},\n",
    "    'item_volume': {'centilitre', 'cubic foot', 'cubic inch', 'cup', 'decilitre', 'fluid ounce', 'gallon', 'litre',\n",
    "                    'microlitre', 'millilitre', 'pint', 'quart'}\n",
    "}\n",
    "\n",
    "# Function to download the image\n",
    "def download_image(image_url):\n",
    "    response = requests.get(image_url)\n",
    "    if response.status_code == 200:\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        return img\n",
    "    else:\n",
    "        raise Exception(f\"Failed to download image. Status code: {response.status_code}\")\n",
    "\n",
    "# Function to preprocess the image for OCR\n",
    "def preprocess_image(image):\n",
    "    image_np = np.array(image)\n",
    "    image_bgr = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)\n",
    "    gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    img_resized = cv2.resize(thresh, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "    return img_resized\n",
    "\n",
    "# Function to extract text from the image\n",
    "def extract_text_from_image(image):\n",
    "    preprocessed_image = Image.fromarray(image)\n",
    "    text = pytesseract.image_to_string(preprocessed_image)\n",
    "    return text\n",
    "\n",
    "# Function to extract numeric values without units from text\n",
    "def extract_constants(text):\n",
    "    constants = re.findall(r'\\d+\\.?\\d*', text)\n",
    "    return constants\n",
    "\n",
    "# Function to extract entity value based on units from text\n",
    "def extract_entity_value(entity_name, text):\n",
    "    # Find numbers followed by a unit\n",
    "    pattern = r'(\\d+\\.?\\d*)\\s*(\\w+)'\n",
    "    matches = re.findall(pattern, text)\n",
    "\n",
    "    for match in matches:\n",
    "        value, unit = match\n",
    "        if unit in entity_unit_map.get(entity_name, set()):\n",
    "            return f\"{value} {unit}\"\n",
    "\n",
    "    # If no match with units, check for standalone numeric values\n",
    "    constants = extract_constants(text)\n",
    "    if constants:\n",
    "        return constants[0]  # Use the first constant without a unit\n",
    "\n",
    "    return None\n",
    "\n",
    "# Function to process a single image and extract the entity value\n",
    "def process_image(image_url, entity_name):\n",
    "    image = download_image(image_url)\n",
    "    preprocessed_image = preprocess_image(image)\n",
    "    text = extract_text_from_image(preprocessed_image)\n",
    "\n",
    "    entity_value = extract_entity_value(entity_name, text)\n",
    "\n",
    "    return entity_value\n",
    "\n",
    "# Function to predict the unit if no valid entity value is found\n",
    "def predict_unit(group_id_value, entity_name_value, ct, classifier, unit_mapping):\n",
    "    manual_input = {\n",
    "        'group_id': [group_id_value],\n",
    "        'entity_name': [entity_name_value],\n",
    "        'entity_value': [None],\n",
    "        'image_link': [None],\n",
    "        'product_id': [None]\n",
    "    }\n",
    "    single_row_df = pd.DataFrame(manual_input)\n",
    "    encoded_row = ct.transform(single_row_df)\n",
    "    encoded_column_names = ct.transformers_[0][1].get_feature_names_out(['entity_name'])\n",
    "    encoded_entity_name_df = pd.DataFrame(encoded_row[:, :len(encoded_column_names)], columns=encoded_column_names)\n",
    "    group_id_df = pd.DataFrame(single_row_df[['group_id']].values, columns=['group_id'])\n",
    "    input_data = pd.concat([group_id_df, encoded_entity_name_df], axis=1)\n",
    "    predicted_unit_label = classifier.predict(input_data)\n",
    "    predicted_unit = unit_mapping[predicted_unit_label[0]]\n",
    "    return predicted_unit\n",
    "\n",
    "# Main function to process the dataset\n",
    "def process_dataset(csv_file, ct, classifier, unit_mapping):\n",
    "    dataset = pd.read_csv(csv_file)\n",
    "    results = []\n",
    "\n",
    "    for index, row in dataset.iterrows():\n",
    "        group_id = row['group_id']\n",
    "        entity_name = row['entity_name']\n",
    "        image_url = row['image_link']\n",
    "\n",
    "        entity_value = process_image(image_url, entity_name)\n",
    "\n",
    "        if entity_value is None:\n",
    "            entity_value = predict_unit(group_id, entity_name, ct, classifier, unit_mapping)\n",
    "\n",
    "        results.append({'group_id': group_id, 'entity_value': entity_value})\n",
    "\n",
    "    result_df = pd.DataFrame(results)\n",
    "    result_df.to_csv('output_entity_values.csv', index=False)\n",
    "\n",
    "# Load trained model, encoder, and unit mapping\n",
    "with open('encoder.pkl', 'rb') as file:\n",
    "    ct = pickle.load(file)\n",
    "\n",
    "with open('svm_model.pkl', 'rb') as file:\n",
    "    classifier = pickle.load(file)\n",
    "\n",
    "with open('unit_mapping.pkl', 'rb') as file:\n",
    "    unit_mapping = pickle.load(file)\n",
    "\n",
    "# Example of running the process\n",
    "process_dataset('input_file.csv', ct, classifier, unit_mapping)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
