{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e27a90ec-64d1-45fb-8d41-dd0ce24e1cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          image_link  group_id  \\\n",
      "0  https://m.media-amazon.com/images/I/61I9XdN6OF...    748919   \n",
      "1  https://m.media-amazon.com/images/I/71gSRbyXmo...    916768   \n",
      "2  https://m.media-amazon.com/images/I/61BZ4zrjZX...    459516   \n",
      "3  https://m.media-amazon.com/images/I/612mrlqiI4...    459516   \n",
      "4  https://m.media-amazon.com/images/I/617Tl40LOX...    731432   \n",
      "\n",
      "  entity_name_depth entity_name_height entity_name_item_volume  \\\n",
      "0               0.0                0.0                     0.0   \n",
      "1               0.0                0.0                     1.0   \n",
      "2               0.0                0.0                     0.0   \n",
      "3               0.0                0.0                     0.0   \n",
      "4               0.0                0.0                     0.0   \n",
      "\n",
      "  entity_name_item_weight entity_name_maximum_weight_recommendation  \\\n",
      "0                     1.0                                       0.0   \n",
      "1                     0.0                                       0.0   \n",
      "2                     1.0                                       0.0   \n",
      "3                     1.0                                       0.0   \n",
      "4                     1.0                                       0.0   \n",
      "\n",
      "  entity_name_voltage entity_name_wattage entity_name_width    entity_value  \n",
      "0                 0.0                 0.0               0.0      500.0 gram  \n",
      "1                 0.0                 0.0               0.0         1.0 cup  \n",
      "2                 0.0                 0.0               0.0      0.709 gram  \n",
      "3                 0.0                 0.0               0.0      0.709 gram  \n",
      "4                 0.0                 0.0               0.0  1400 milligram  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "dataset = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Apply one-hot encoding on 'entity_name' column (before dropping it)\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[('encoder', OneHotEncoder(handle_unknown='ignore'), ['entity_name'])],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "x_encoded = ct.fit_transform(dataset)\n",
    "\n",
    "# Convert encoded data to DataFrame\n",
    "x_encoded_df = pd.DataFrame(x_encoded)\n",
    "\n",
    "# Drop original 'entity_name' column from the dataset\n",
    "dataset_drop_entity = dataset.drop(columns=['entity_name'])\n",
    "\n",
    "# Get the one-hot encoded column names\n",
    "encoded_column_names = ct.transformers_[0][1].get_feature_names_out(['entity_name'])\n",
    "\n",
    "# Create DataFrame for one-hot encoded columns\n",
    "onehot_cols = pd.DataFrame(x_encoded[:, :len(encoded_column_names)], columns=encoded_column_names)\n",
    "\n",
    "# Concatenate original columns (excluding 'entity_name') and one-hot encoded columns\n",
    "dataset_onehot = pd.concat([dataset_drop_entity, onehot_cols], axis=1)\n",
    "\n",
    "# Move 'entity_value' column to the last position\n",
    "cols = [col for col in dataset_onehot.columns if col != 'entity_value']  # All columns except 'entity_value'\n",
    "cols.append('entity_value')  # Add 'entity_value' at the end\n",
    "\n",
    "# Reorder the DataFrame\n",
    "dataset_onehot = dataset_onehot[cols]\n",
    "\n",
    "# Show the first few rows\n",
    "print(dataset_onehot.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dac8d42-53d9-46a9-bc89-2084763965ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['image_link', 'group_id', 'entity_name_depth', 'entity_name_height',\n",
      "       'entity_name_item_volume', 'entity_name_item_weight',\n",
      "       'entity_name_maximum_weight_recommendation', 'entity_name_voltage',\n",
      "       'entity_name_wattage', 'entity_name_width', 'entity_value'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(dataset_onehot.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2833d0f-593e-4bcf-b699-44a4ec2c2cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_onehot.to_csv(\"rearranged_dataset2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "285a4e40-1b96-4e82-9615-75a9edf0687e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               image_link  group_id  \\\n",
      "0       https://m.media-amazon.com/images/I/61I9XdN6OF...    748919   \n",
      "1       https://m.media-amazon.com/images/I/71gSRbyXmo...    916768   \n",
      "2       https://m.media-amazon.com/images/I/61BZ4zrjZX...    459516   \n",
      "3       https://m.media-amazon.com/images/I/612mrlqiI4...    459516   \n",
      "4       https://m.media-amazon.com/images/I/617Tl40LOX...    731432   \n",
      "...                                                   ...       ...   \n",
      "263854  https://m.media-amazon.com/images/I/612J1R1xHl...    558806   \n",
      "263855  https://m.media-amazon.com/images/I/61Blzh2+28...    470067   \n",
      "263856  https://m.media-amazon.com/images/I/51MsegDL9V...    204245   \n",
      "263857  https://m.media-amazon.com/images/I/510KhVw4VS...    752266   \n",
      "263858  https://m.media-amazon.com/images/I/51lzTNLQ-6...    416664   \n",
      "\n",
      "        entity_name_depth  entity_name_height  entity_name_item_volume  \\\n",
      "0                     0.0                 0.0                      0.0   \n",
      "1                     0.0                 0.0                      1.0   \n",
      "2                     0.0                 0.0                      0.0   \n",
      "3                     0.0                 0.0                      0.0   \n",
      "4                     0.0                 0.0                      0.0   \n",
      "...                   ...                 ...                      ...   \n",
      "263854                0.0                 1.0                      0.0   \n",
      "263855                0.0                 1.0                      0.0   \n",
      "263856                0.0                 1.0                      0.0   \n",
      "263857                0.0                 1.0                      0.0   \n",
      "263858                0.0                 1.0                      0.0   \n",
      "\n",
      "        entity_name_item_weight  entity_name_maximum_weight_recommendation  \\\n",
      "0                           1.0                                        0.0   \n",
      "1                           0.0                                        0.0   \n",
      "2                           1.0                                        0.0   \n",
      "3                           1.0                                        0.0   \n",
      "4                           1.0                                        0.0   \n",
      "...                         ...                                        ...   \n",
      "263854                      0.0                                        0.0   \n",
      "263855                      0.0                                        0.0   \n",
      "263856                      0.0                                        0.0   \n",
      "263857                      0.0                                        0.0   \n",
      "263858                      0.0                                        0.0   \n",
      "\n",
      "        entity_name_voltage  entity_name_wattage  entity_name_width  value  \\\n",
      "0                       0.0                  0.0                0.0  500.0   \n",
      "1                       0.0                  0.0                0.0    1.0   \n",
      "2                       0.0                  0.0                0.0  0.709   \n",
      "3                       0.0                  0.0                0.0  0.709   \n",
      "4                       0.0                  0.0                0.0   1400   \n",
      "...                     ...                  ...                ...    ...   \n",
      "263854                  0.0                  0.0                0.0    5.0   \n",
      "263855                  0.0                  0.0                0.0    8.5   \n",
      "263856                  0.0                  0.0                0.0   43.2   \n",
      "263857                  0.0                  0.0                0.0    9.1   \n",
      "263858                  0.0                  0.0                0.0   27.5   \n",
      "\n",
      "              unit  \n",
      "0             gram  \n",
      "1              cup  \n",
      "2             gram  \n",
      "3             gram  \n",
      "4        milligram  \n",
      "...            ...  \n",
      "263854  centimetre  \n",
      "263855        inch  \n",
      "263856  centimetre  \n",
      "263857  centimetre  \n",
      "263858  centimetre  \n",
      "\n",
      "[263859 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('rearranged_dataset2.csv')\n",
    "\n",
    "# Split entity_value into numeric and unit\n",
    "df[['value', 'unit']] = df['entity_value'].str.extract(r'(\\d+\\.?\\d*)\\s*(\\D+)')\n",
    "df = df.drop(columns=['entity_value'])\n",
    "\n",
    "\n",
    "df.to_csv('updated_file.csv', index=False)\n",
    "\n",
    "# Show the updated DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "674c898b-063d-4543-b617-6a93c005ec40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               image_link  group_id  \\\n",
      "0       https://m.media-amazon.com/images/I/61I9XdN6OF...    748919   \n",
      "1       https://m.media-amazon.com/images/I/71gSRbyXmo...    916768   \n",
      "2       https://m.media-amazon.com/images/I/61BZ4zrjZX...    459516   \n",
      "3       https://m.media-amazon.com/images/I/612mrlqiI4...    459516   \n",
      "4       https://m.media-amazon.com/images/I/617Tl40LOX...    731432   \n",
      "...                                                   ...       ...   \n",
      "263854  https://m.media-amazon.com/images/I/612J1R1xHl...    558806   \n",
      "263855  https://m.media-amazon.com/images/I/61Blzh2+28...    470067   \n",
      "263856  https://m.media-amazon.com/images/I/51MsegDL9V...    204245   \n",
      "263857  https://m.media-amazon.com/images/I/510KhVw4VS...    752266   \n",
      "263858  https://m.media-amazon.com/images/I/51lzTNLQ-6...    416664   \n",
      "\n",
      "        entity_name_depth  entity_name_height  entity_name_item_volume  \\\n",
      "0                     0.0                 0.0                      0.0   \n",
      "1                     0.0                 0.0                      1.0   \n",
      "2                     0.0                 0.0                      0.0   \n",
      "3                     0.0                 0.0                      0.0   \n",
      "4                     0.0                 0.0                      0.0   \n",
      "...                   ...                 ...                      ...   \n",
      "263854                0.0                 1.0                      0.0   \n",
      "263855                0.0                 1.0                      0.0   \n",
      "263856                0.0                 1.0                      0.0   \n",
      "263857                0.0                 1.0                      0.0   \n",
      "263858                0.0                 1.0                      0.0   \n",
      "\n",
      "        entity_name_item_weight  entity_name_maximum_weight_recommendation  \\\n",
      "0                           1.0                                        0.0   \n",
      "1                           0.0                                        0.0   \n",
      "2                           1.0                                        0.0   \n",
      "3                           1.0                                        0.0   \n",
      "4                           1.0                                        0.0   \n",
      "...                         ...                                        ...   \n",
      "263854                      0.0                                        0.0   \n",
      "263855                      0.0                                        0.0   \n",
      "263856                      0.0                                        0.0   \n",
      "263857                      0.0                                        0.0   \n",
      "263858                      0.0                                        0.0   \n",
      "\n",
      "        entity_name_voltage  entity_name_wattage  entity_name_width     value  \\\n",
      "0                       0.0                  0.0                0.0   500.000   \n",
      "1                       0.0                  0.0                0.0     1.000   \n",
      "2                       0.0                  0.0                0.0     0.709   \n",
      "3                       0.0                  0.0                0.0     0.709   \n",
      "4                       0.0                  0.0                0.0  1400.000   \n",
      "...                     ...                  ...                ...       ...   \n",
      "263854                  0.0                  0.0                0.0     5.000   \n",
      "263855                  0.0                  0.0                0.0     8.500   \n",
      "263856                  0.0                  0.0                0.0    43.200   \n",
      "263857                  0.0                  0.0                0.0     9.100   \n",
      "263858                  0.0                  0.0                0.0    27.500   \n",
      "\n",
      "              unit  unit_label  \n",
      "0             gram           0  \n",
      "1              cup           1  \n",
      "2             gram           0  \n",
      "3             gram           0  \n",
      "4        milligram           2  \n",
      "...            ...         ...  \n",
      "263854  centimetre          19  \n",
      "263855        inch          31  \n",
      "263856  centimetre          19  \n",
      "263857  centimetre          19  \n",
      "263858  centimetre          19  \n",
      "\n",
      "[263859 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('updated_file.csv')\n",
    "\n",
    "# Factorize the 'unit' column to assign numeric labels\n",
    "df['unit_label'] = pd.factorize(df['unit'])[0]\n",
    "\n",
    "# Save the modified DataFrame (optional)\n",
    "df.to_csv('updated_file_with_unit_labels.csv', index=False)\n",
    "\n",
    "# Save the unit label mapping\n",
    "unit_mapping = pd.factorize(df['unit'])[1]\n",
    "\n",
    "import pickle\n",
    "with open('unit_mapping.pkl', 'wb') as file:\n",
    "    pickle.dump(unit_mapping, file)\n",
    "\n",
    "# Show the updated DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e147db1d-8b26-40d9-8cb4-b947d98aa417",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv('updated_file_with_unit_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b94331b2-ae83-40a8-be5b-24b4e31fe72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataset.iloc[:, 1:10]\n",
    "y=dataset.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57c40bd4-171f-4ada-a153-3709074bae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3b61018-79aa-4198-b317-75cdfefc5c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier=DecisionTreeClassifier(criterion='entropy',random_state=0)\n",
    "classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a634a3b8-46aa-4ec8-b3e2-aa89585555b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01465552-0b78-4de5-b555-fd5f19ab27a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11686     0   764 ...     0     0     0]\n",
      " [    0     0     0 ...     0     0     0]\n",
      " [  607     0   990 ...     0     0     0]\n",
      " ...\n",
      " [    5     0     0 ...     0     0     0]\n",
      " [    0     0     0 ...     0    29     0]\n",
      " [    0     0     0 ...     0     0     0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6143977867050708"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb966eb2-60a1-497a-aee1-36f0b5707dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the encoder (ColumnTransformer) after training\n",
    "with open('encoder.pkl', 'wb') as file:\n",
    "    pickle.dump(ct, file)\n",
    "\n",
    "# Save the trained SVM model\n",
    "with open('svm_model.pkl', 'wb') as file:\n",
    "    pickle.dump(classifier, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e96da31-f417-49ab-96f6-f30eaab305db",
   "metadata": {},
   "source": [
    "## add the group_id and entity_name in this at last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2abf7aa-b893-47c7-82a0-be2bd62a2325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted unit is gram\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Load the saved encoder, SVM model, and unit mapping\n",
    "with open('encoder.pkl', 'rb') as file:\n",
    "    ct = pickle.load(file)\n",
    "\n",
    "with open('svm_model.pkl', 'rb') as file:\n",
    "    classifier = pickle.load(file)\n",
    "\n",
    "with open('unit_mapping.pkl', 'rb') as file:\n",
    "    unit_mapping = pickle.load(file)\n",
    "\n",
    "# Function to make predictions based on manual input\n",
    "def predict_unit(group_id_value, entity_name_value):\n",
    "    # Create a DataFrame with the manual input, including all required columns\n",
    "    manual_input = {\n",
    "        'group_id': [group_id_value],       # Use group_id here\n",
    "        'entity_name': [entity_name_value],\n",
    "        'entity_value': [None],\n",
    "        'image_link': [None],               # Add placeholder values for missing columns\n",
    "        'product_id': [None]                # Add placeholder values for missing columns\n",
    "    }\n",
    "    single_row_df = pd.DataFrame(manual_input)\n",
    "\n",
    "    # Apply one-hot encoding on the 'entity_name' column of the manual input\n",
    "    encoded_row = ct.transform(single_row_df)\n",
    "\n",
    "    # Get the encoded column names (same as training)\n",
    "    encoded_column_names = ct.transformers_[0][1].get_feature_names_out(['entity_name'])\n",
    "\n",
    "    # Create DataFrame for encoded entity_name with proper column names\n",
    "    encoded_entity_name_df = pd.DataFrame(encoded_row[:, :len(encoded_column_names)], columns=encoded_column_names)\n",
    "\n",
    "    # Combine 'group_id' and the encoded columns\n",
    "    group_id_df = pd.DataFrame(single_row_df[['group_id']].values, columns=['group_id'])\n",
    "\n",
    "    # Prepare the final input row for prediction by combining 'group_id' and encoded columns\n",
    "    input_data = pd.concat([group_id_df, encoded_entity_name_df], axis=1)\n",
    "\n",
    "    # Predict the unit label using the classifier\n",
    "    predicted_unit_label = classifier.predict(input_data)\n",
    "\n",
    "    # Map the predicted numeric label to the original unit name\n",
    "    predicted_unit = unit_mapping[predicted_unit_label[0]]\n",
    "\n",
    "    return predicted_unit\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    group_id_input = 281678  # Replace with your input\n",
    "    entity_name_input = 'item_weight'  # Replace with your input\n",
    "\n",
    "    predicted_unit = predict_unit(group_id_input, entity_name_input)\n",
    "    print(f\"Predicted unit is {predicted_unit}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d436aa93-61a9-4234-b896-2d042e16ff7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predicted_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "952cbb19-d872-4b23-b145-e166a2640e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "420488e2-1059-4c9a-9e3c-38966cf2bf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files (x86)\\Tesseract-OCR\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16125493-820f-46eb-a6fa-b8e7aee48f2c",
   "metadata": {},
   "source": [
    "## Add the link to the image here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1445b3e9-4654-42e9-b41a-476a03129296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image successfully downloaded: test_image.jpg\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def download_image(image_url):\n",
    "    save_path = \"test_image.jpg\"  # Constant save path\n",
    "    try:\n",
    "        # Send a GET request to fetch the image\n",
    "        response = requests.get(image_url)\n",
    "        # Check if the request was successful (status code 200)\n",
    "        if response.status_code == 200:\n",
    "            # Write the image content to a file\n",
    "            with open(save_path, 'wb') as file:\n",
    "                file.write(response.content)\n",
    "            print(f\"Image successfully downloaded: {save_path}\")\n",
    "        else:\n",
    "            print(f\"Failed to retrieve image. Status code: {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example usage\n",
    "image_url = 'https://m.media-amazon.com/images/I/81dzao1Ob4L.jpg'  # Replace with your image URL\n",
    "download_image(image_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1debae8a-33e7-454c-9b62-dac478fd4243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PACKAGING CHANGED\n",
      "\n",
      "a\n",
      "=\n",
      "orien\n",
      "Comary bitin |\n",
      "=\n",
      "== =\n",
      "es\n",
      "\n",
      "pel = ee\n",
      "SaaS. SERS\n",
      "\n",
      "BEFORE\n",
      "\n",
      "ae he wore witht ood yu 0 of he herb keeps blood pressure «conrad bobo keeps\n",
      "‘We wark with o wnble network of fermen ond hormond balance\n",
      "\n",
      "DIRECTION OF USE\n",
      "Sem medcing herb spearmint con be mode into herbal\n",
      "\n",
      "Meee tie etn\n",
      "\n",
      "‘Coetnn 1 Paden |\n",
      "Schtemthy topsite pete oop\n",
      "\n",
      "Hor . Neda. GOO same wihin 2 eesthe chor opening th packet\n",
      "Fer cotemser feedback a NET WEIGHT : 100 g (3.53 oz]\n",
      "Sagres ay Bit\n",
      "eoreverichengonics crm A] MRP Rs. :\n",
      "i lendboak com serichengrnics/ .\n",
      "@ bechagrencom/ erick ovyenica/| BATCH NO. :\n",
      "\n",
      "dhnigp 0 puri even, .\n",
      "Merten tcetin genres PRD:\n",
      "\n",
      "E r\n",
      "lb 8 jE\n",
      "tila USE BY :\n",
      "\n",
      "AFTER\n",
      "\n",
      "Note: Packaging may vary for a brief period of time.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "img = cv2.imread(\"test_image.jpg\")\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Gaussian Blur to remove noise\n",
    "gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "# Apply Otsu's thresholding after Gaussian filtering\n",
    "_, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "# Use dilation to strengthen the text and erode to remove noise\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "dilate = cv2.dilate(thresh, kernel, iterations=1)\n",
    "erode = cv2.erode(dilate, kernel, iterations=1)\n",
    "\n",
    "# Resize the image\n",
    "img_resized = cv2.resize(thresh, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "edges = cv2.Canny(gray, 100, 200)\n",
    "\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# Convert the OpenCV image to a format that Tesseract can understand\n",
    "preprocessed_image = Image.fromarray(thresh)\n",
    "\n",
    "# Extract text using Tesseract\n",
    "text = pytesseract.image_to_string(preprocessed_image)\n",
    "\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d3dacd38-4c67-4b2e-ab52-223a363d3def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c9990836-b21f-434d-98be-51148916e0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# Extract all numbers (integer and float) from the string\n",
    "numbers = re.findall(r'\\d+\\.?\\d*', text)\n",
    "\n",
    "# Convert them to float\n",
    "numbers = [float(num) for num in numbers]\n",
    "\n",
    "# Randomly select one number\n",
    "selected_number = random.choice(numbers)\n",
    "\n",
    "# Concatenate with your predicted unit\n",
    "result = f\"{selected_number} {predicted_unit}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34f3de1-8f49-4156-a55a-6d028d7062a9",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88c58739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pytesseract\n",
    "import re\n",
    "\n",
    "def process_and_extract_integers(image_url):\n",
    "    \"\"\"\n",
    "    Downloads an image from the provided URL, preprocesses it (resizes and converts to grayscale),\n",
    "    and then extracts all integer values from the image using OCR. If no integers are found, it returns None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Step 1: Download the image\n",
    "        response = requests.get(image_url)\n",
    "        if response.status_code == 200:\n",
    "            img = Image.open(BytesIO(response.content))\n",
    "        else:\n",
    "            raise Exception(f\"Failed to download image. Status code: {response.status_code}\")\n",
    "        \n",
    "        # Step 2: Preprocess the image\n",
    "        # Convert the Pillow image to a NumPy array\n",
    "        image_np = np.array(img)\n",
    "\n",
    "        # Convert from RGB to BGR for OpenCV\n",
    "        image_bgr = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Resize the image to 500x500 pixels\n",
    "        image_resized = cv2.resize(image_bgr, (500, 500))\n",
    "\n",
    "        # Convert to grayscale\n",
    "        gray_image = cv2.cvtColor(image_resized, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Step 3: Extract integers using OCR\n",
    "        # Perform OCR on the grayscale image\n",
    "        text = pytesseract.image_to_string(gray_image)\n",
    "\n",
    "        # Define a pattern to find integers\n",
    "        integer_pattern = r'\\d+'\n",
    "\n",
    "        # Find all integers in the OCR extracted text\n",
    "        matches = re.findall(integer_pattern, text)\n",
    "\n",
    "        # Convert matches to integers\n",
    "        integers = [int(match) for match in matches]\n",
    "\n",
    "        if integers:\n",
    "            # Calculate and return the average of the integers\n",
    "            return sum(integers) / len(integers)\n",
    "        else:\n",
    "            # Return None if no integers are found\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c2f2110-5e69-46b1-a28e-deab292240a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Results saved to test_out.csv\n"
     ]
    }
   ],
   "source": [
    "def process_csv(input_csv_path, output_csv_path):\n",
    "    input_data = pd.read_csv(input_csv_path)\n",
    "    output_data = []\n",
    "\n",
    "    for idx,row in input_data.iterrows():\n",
    "        group_id = row['group_id']\n",
    "        entity_name = row['entity_name']\n",
    "\n",
    "        # extracted_value = process_and_extract_integers(image_url)\n",
    "        # if extracted_value is None:\n",
    "        #     output_data.append({\"index\": row['index'], \"prediction\": None})\n",
    "        #     continue\n",
    "        \n",
    "        prediction = predict_unit(group_id, entity_name)\n",
    "        output_data.append({\"index\": row['index'], \"prediction\": prediction})\n",
    "\n",
    "    output_df = pd.DataFrame(output_data)\n",
    "    output_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Processing complete. Results saved to {output_csv_path}\")\n",
    "\n",
    "input_csv_path = 'test.csv'\n",
    "output_csv_path = 'test_out.csv'\n",
    "            \n",
    "process_csv(input_csv_path, output_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b000a347-d944-42fe-95fd-30066f90a515",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
